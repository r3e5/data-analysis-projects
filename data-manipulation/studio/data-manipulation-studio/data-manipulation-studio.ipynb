{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1894ccac",
   "metadata": {},
   "source": [
    "# Data Manipulation Studio\n",
    "\n",
    "For this studio, we will revisit our California farmers looking for advice on growing pumpkins and the same [pumpkins dataset](https://www.kaggle.com/usda/a-year-of-pumpkin-prices) as provided by the U.S. Department of Agriculture. You may have to clean data in the process of data manipulation, so feel free to pull up your notebook from the last class's studio.\n",
    "\n",
    "We will now be focusing our attention on a different region in the United States, the Northeast. When you open up the `dataset` folder, you will have 13 CSVs, including the San Francisco and Los Angeles data from the last lesson. The 13 CSVs are each a different terminal market in the United States.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Import the CSVs for each of the following cities: Baltimore, Boston, New York, and Philadelphia. Set up a dataframe for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c9a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and CSVs. Make some dataframes!\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "baltimore_data = pd.read_csv(\"dataset/baltimore_9-24-2016_9-30-2017.csv\")\n",
    "new_york_data = pd.read_csv(\"dataset/new-york_9-24-2016_9-30-2017.csv\")\n",
    "boston_data = pd.read_csv(\"dataset/boston_9-24-2016_9-30-2017.csv\")\n",
    "philly_data = pd.read_csv(\"dataset/boston_9-24-2016_9-30-2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda42f",
   "metadata": {},
   "source": [
    "## Clean Your Data\n",
    "\n",
    "In the last lesson, we cleaned the data to related to San Francisco. Pull up your notebook from the last lesson and use your cleaning skills to clean the dataframes as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98abc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean your data here!\n",
    "\n",
    "# print(\"The data missing for baltimore is:\")\n",
    "# for col in baltimore_data.columns:\n",
    "#     pct_missing = np.mean(baltimore_data[col].isnull())\n",
    "#     print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "# print(\"The data missing for new york is:\")\n",
    "# for col in new_york_data.columns:\n",
    "#     pct_missing = np.mean(new_york_data[col].isnull())\n",
    "#     print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "# print(\"The data missing for boston is:\")\n",
    "# for col in boston_data.columns:\n",
    "#     pct_missing = np.mean(boston_data[col].isnull())\n",
    "#     print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "# print(\"The data missing for philly is:\")\n",
    "# for col in philly_data.columns:\n",
    "#     pct_missing = np.mean(philly_data[col].isnull())\n",
    "#     print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "baltimore_data = baltimore_data.drop([\"Type\",\"Sub Variety\",\"Grade\",\"Origin District\",\n",
    "                                     \"Color\",\"Environment\",\"Quality\",\"Condition\",\n",
    "                                     \"Appearance\",\"Storage\",\"Crop\",\"Trans Mode\"],axis=1)\n",
    "new_york_data = new_york_data.drop([\"Type\",\"Sub Variety\",\"Grade\",\"Origin District\",\n",
    "                                     \"Color\",\"Environment\",\"Quality\",\"Condition\",\n",
    "                                     \"Appearance\",\"Storage\",\"Crop\",\"Trans Mode\"],axis=1)\n",
    "boston_data = boston_data.drop([\"Type\",\"Sub Variety\",\"Grade\",\"Origin District\",\n",
    "                                     \"Color\",\"Environment\",\"Quality\",\"Condition\",\n",
    "                                     \"Appearance\",\"Storage\",\"Crop\",\"Trans Mode\"],axis=1)\n",
    "philly_data = philly_data.drop([\"Type\",\"Sub Variety\",\"Grade\",\"Origin District\",\n",
    "                                     \"Color\",\"Environment\",\"Quality\",\"Condition\",\n",
    "                                     \"Appearance\",\"Storage\",\"Crop\",\"Trans Mode\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b01b9",
   "metadata": {},
   "source": [
    "## Combine Your Data\n",
    "\n",
    "Now that you have four clean sets of data, combine all four into one dataframe that represents the entire Northeast region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da059f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Commodity Name  City Name             Package      Variety  \\\n",
      "baltimore 0         PUMPKINS  BALTIMORE        24 inch bins          NaN   \n",
      "          1         PUMPKINS  BALTIMORE        24 inch bins          NaN   \n",
      "          2         PUMPKINS  BALTIMORE        24 inch bins  HOWDEN TYPE   \n",
      "          3         PUMPKINS  BALTIMORE        24 inch bins  HOWDEN TYPE   \n",
      "          4         PUMPKINS  BALTIMORE        24 inch bins  HOWDEN TYPE   \n",
      "...                      ...        ...                 ...          ...   \n",
      "philly    347       PUMPKINS     BOSTON  1/2 bushel cartons    MINIATURE   \n",
      "          348       PUMPKINS     BOSTON  1/2 bushel cartons    MINIATURE   \n",
      "          349       PUMPKINS     BOSTON  1/2 bushel cartons    MINIATURE   \n",
      "          350       PUMPKINS     BOSTON  1/2 bushel cartons    MINIATURE   \n",
      "          351       PUMPKINS     BOSTON  1/2 bushel cartons    MINIATURE   \n",
      "\n",
      "                     Date  Low Price  High Price  Mostly Low  Mostly High  \\\n",
      "baltimore 0    04/29/2017        270       280.0         270        280.0   \n",
      "          1    05/06/2017        270       280.0         270        280.0   \n",
      "          2    09/24/2016        160       160.0         160        160.0   \n",
      "          3    09/24/2016        160       160.0         160        160.0   \n",
      "          4    11/05/2016         90       100.0          90        100.0   \n",
      "...                   ...        ...         ...         ...          ...   \n",
      "philly    347  10/22/2016         15        18.0          15         15.0   \n",
      "          348  10/29/2016         15        18.0          15         15.0   \n",
      "          349  10/29/2016         15        18.0          15         15.0   \n",
      "          350  11/05/2016         15        18.0          15         15.0   \n",
      "          351  11/05/2016         15        18.0          15         15.0   \n",
      "\n",
      "                      Origin Item Size Unit of Sale Repack  \n",
      "baltimore 0              NaN       lge          NaN      E  \n",
      "          1              NaN       lge          NaN      E  \n",
      "          2         DELAWARE       med          NaN      N  \n",
      "          3         VIRGINIA       med          NaN      N  \n",
      "          4         MARYLAND       lge          NaN      N  \n",
      "...                      ...       ...          ...    ...  \n",
      "philly    347  MASSACHUSETTS       sml          NaN      N  \n",
      "          348  MASSACHUSETTS       sml          NaN      N  \n",
      "          349  MASSACHUSETTS       sml          NaN      N  \n",
      "          350  MASSACHUSETTS       sml          NaN      N  \n",
      "          351  MASSACHUSETTS       sml          NaN      N  \n",
      "\n",
      "[969 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Combine the four dataframes into one!\n",
    "data = pd.concat([baltimore_data,new_york_data,boston_data,philly_data],axis=0,\n",
    "                 keys= [\"baltimore\", \"new_york\",\"boston\",\"philly\"])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590082f",
   "metadata": {},
   "source": [
    "## Answer Some Questions\n",
    "\n",
    "Use `groupby()` and `agg()` to answer the following two questions:\n",
    "\n",
    "1. What is the mean low and high prices for each type of unit of sale in the Northeast region? In the last lesson, we learned that a unit of sale could be something like a bin or individually. \n",
    "2. What is the average number of pumpkins for each variety that came into terminal markets for the year by region? Pumpkin varieties include Howden and Fairytale pumpkins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c839639a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low Price</th>\n",
       "      <th>High Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unit of Sale</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EACH</th>\n",
       "      <td>47.916667</td>\n",
       "      <td>59.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER BIN</th>\n",
       "      <td>193.376068</td>\n",
       "      <td>215.341880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Low Price  High Price\n",
       "Unit of Sale                        \n",
       "EACH           47.916667   59.166667\n",
       "PER BIN       193.376068  215.341880"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here to find the mean low and high prices in the Northeast region for each type of unit of sale.\n",
    "data[['Low Price','High Price']].groupby(data['Unit of Sale']).agg('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b23352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety\n",
      "HOWDEN TYPE                 109.333333\n",
      "PIE TYPE                     98.666667\n",
      "MINIATURE                    37.666667\n",
      "BIG MACK TYPE                28.000000\n",
      "FAIRYTALE                    19.333333\n",
      "CINDERELLA                   17.666667\n",
      "KNUCKLE HEAD                  5.000000\n",
      "BLUE TYPE                     4.666667\n",
      "MIXED HEIRLOOM VARIETIES      1.333333\n",
      "HOWDEN WHITE TYPE             0.666667\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Put your code here to find the average number of pumpkins coming into terminal markets of each variety.\n",
    "num_cities = len(data['City Name'].unique())\n",
    "print(data['Variety'].value_counts()/num_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5cff4",
   "metadata": {},
   "source": [
    "## Bonus Mission\n",
    "\n",
    "Try answering the same questions for the Midwest (Chicago, Detroit, and St. Louis) or the Southeast (Atlanta, Columbia, and Miami) regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d22b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the bonus mission if you have time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbc152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
